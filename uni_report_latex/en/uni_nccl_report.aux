\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}TODO / Structure (from Markdown)}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Table of Contents}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Main content chunks / concepts}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Abstract}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}About NCCL}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Comparison to MPI}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Relevant NCCL internals}{4}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Thread creation: User API $\to $ NCCL internal init $\to $ create ProxyService $\to $ create ProxyProgress.}}{5}{figure.1}\protected@file@percent }
\newlabel{fig:thread-creation}{{1}{5}{Thread creation: User API $\to $ NCCL internal init $\to $ create ProxyService $\to $ create ProxyProgress}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Flow from User API to \texttt  {ncclProxyPost()}}}{6}{figure.2}\protected@file@percent }
\newlabel{fig:proxy-post}{{2}{6}{Flow from User API to \texttt {ncclProxyPost()}}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {/src/proxy.cc} \texttt  {ncclProxyProgress()} progressing loop: progress ops, then get posted ops (or wait). }}{7}{figure.3}\protected@file@percent }
\newlabel{fig:proxy-progress-loop}{{3}{7}{\textbf {/src/proxy.cc} \texttt {ncclProxyProgress()} progressing loop: progress ops, then get posted ops (or wait)}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}The Profiler API}{7}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}How NCCL detects the profiler plugin}{7}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces User API $\to $ NCCL init $\to $ load profiler plugin and call \texttt  {profiler->init()}.}}{9}{figure.4}\protected@file@percent }
\newlabel{fig:profiler-init}{{4}{9}{User API $\to $ NCCL init $\to $ load profiler plugin and call \texttt {profiler->init()}}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The profiler API definition}{9}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}init}{10}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}startEvent}{11}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}stopEvent}{12}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Flow from NCCL API calls to profiler events. In case of \texttt  {ncclGroupStart / ncclGroupEnd}. multiple events of everything (except GroupApi) are called. internally, some Collectives (e.g. ncclAlltoAll) are implemented as many p2p ops, triggering many P2pApi and P2p events. Implementation: \textbf  {/src/init.cc}, \textbf  {/src/plugin/profiler.cc}.}}{13}{figure.5}\protected@file@percent }
\newlabel{fig:profiler-events}{{5}{13}{Flow from NCCL API calls to profiler events. In case of \texttt {ncclGroupStart / ncclGroupEnd}. multiple events of everything (except GroupApi) are called. internally, some Collectives (e.g. ncclAlltoAll) are implemented as many p2p ops, triggering many P2pApi and P2p events. Implementation: \textbf {/src/init.cc}, \textbf {/src/plugin/profiler.cc}}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \texttt  {ncclProxyProgress}: progressOps emits ProxyStep/KernelCh/NetPlugin events. getPostedOps emits ProxyOp events. Several events ProxyCtrl are also emitted}}{14}{figure.6}\protected@file@percent }
\newlabel{fig:proxy-event-emission}{{6}{14}{\texttt {ncclProxyProgress}: progressOps emits ProxyStep/KernelCh/NetPlugin events. getPostedOps emits ProxyOp events. Several events ProxyCtrl are also emitted}{figure.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}recordEventState}{15}{subsubsection.4.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5}finalize}{15}{subsubsection.4.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces User API $\to $ \texttt  {commReclaim()} $\to $ \texttt  {finalize()} $\to $ plugin unload.}}{15}{figure.7}\protected@file@percent }
\newlabel{fig:profiler-finalize}{{7}{15}{User API $\to $ \texttt {commReclaim()} $\to $ \texttt {finalize()} $\to $ plugin unload}{figure.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.6}name}{16}{subsubsection.4.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Code Examples}{16}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Single Process Multiple Devices}{17}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Single-GPU single-process-multiple-devices with ncclGroup trace: This visualization shows a view on an AllReduce collective, where all ranks are managed by a single thread on the same process.}}{18}{figure.8}\protected@file@percent }
\newlabel{fig:single-gpu-single-process-ncclgroup-finalize}{{8}{18}{Single-GPU single-process-multiple-devices with ncclGroup trace: This visualization shows a view on an AllReduce collective, where all ranks are managed by a single thread on the same process}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Single-GPU single-process-multiple-devices with ncclGroup trace: Zoomed in TODO}}{18}{figure.9}\protected@file@percent }
\newlabel{fig:single-gpu-single-process-ncclgroup-zoom}{{9}{18}{Single-GPU single-process-multiple-devices with ncclGroup trace: Zoomed in TODO}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Single-GPU single-process-multiple-devices with ncclGroup trace: Zoomed in TODO}}{19}{figure.10}\protected@file@percent }
\newlabel{fig:single-gpu-single-process-ncclgroup-zoom2}{{10}{19}{Single-GPU single-process-multiple-devices with ncclGroup trace: Zoomed in TODO}{figure.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Multiple Processes, Multiple Devices per Process, Multiple Threads per Process}{20}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Multi-GPU single-thread-per-device trace: This visualization shows the AllReduce collective being called on 4 different ranks. a single thread corresponds to each rank. First a small bar (row above the green bar), corresponds with the timestamp when the profiler \texttt  {init()} function was called for each rank. since init is called during NCCL's internal communicator creation, this corresponds to roughly when the application called \texttt  {ncclCommInitRank}. Afterwards the application called an \texttt  {ncclAllReduce}. This is visible in the profiler output as when the green bar (\texttt  {groupApi} event) starts. Just below is another tiny bar, which represents the start and stop of the \texttt  {collApi} event. The yellow bar represent the timing where NCCL enqueued the kernel for launch on the GPU (\texttt  {KernelLaunch} event). Two small bars below represnt the \texttt  {group} and \texttt  {coll} events. Besides these 4 threads, NCCL spawned a proxy progress thread for each rank as well. The red \texttt  {ProxyCtrl} event in the row below until that point was indicating that the proxy progress thread was asleep. the new ProxyCtrl event right after is the time it took for the Proxy Progress thread to append proxy ops. Next, multiple proxy ops are starting to be progressed (\texttt  {ProxyOps} events), which in \texttt  {op->progress()} leads to starting \texttt  {KernelCh} network activity. At some point the KernelCh acitvity is completed, the AllReduce collective is finished. The ProxyCtrl event thereafter indicates the proxy progress thread went back to sleep. It is possible to visualize which \texttt  {coll} events across ranks belong to the same collective operation. This is indicated by the red line connecting the events, enabled by the equal valued \texttt  {seqNum} field (provided in \texttt  {eDescr} arg in profiler API \texttt  {init()} function call) across ranks.}}{20}{figure.11}\protected@file@percent }
\newlabel{fig:multi-gpu-single-thread-allreduce}{{11}{20}{Multi-GPU single-thread-per-device trace: This visualization shows the AllReduce collective being called on 4 different ranks. a single thread corresponds to each rank. First a small bar (row above the green bar), corresponds with the timestamp when the profiler \texttt {init()} function was called for each rank. since init is called during NCCL's internal communicator creation, this corresponds to roughly when the application called \texttt {ncclCommInitRank}. Afterwards the application called an \texttt {ncclAllReduce}. This is visible in the profiler output as when the green bar (\texttt {groupApi} event) starts. Just below is another tiny bar, which represents the start and stop of the \texttt {collApi} event. The yellow bar represent the timing where NCCL enqueued the kernel for launch on the GPU (\texttt {KernelLaunch} event). Two small bars below represnt the \texttt {group} and \texttt {coll} events. Besides these 4 threads, NCCL spawned a proxy progress thread for each rank as well. The red \texttt {ProxyCtrl} event in the row below until that point was indicating that the proxy progress thread was asleep. the new ProxyCtrl event right after is the time it took for the Proxy Progress thread to append proxy ops. Next, multiple proxy ops are starting to be progressed (\texttt {ProxyOps} events), which in \texttt {op->progress()} leads to starting \texttt {KernelCh} network activity. At some point the KernelCh acitvity is completed, the AllReduce collective is finished. The ProxyCtrl event thereafter indicates the proxy progress thread went back to sleep. It is possible to visualize which \texttt {coll} events across ranks belong to the same collective operation. This is indicated by the red line connecting the events, enabled by the equal valued \texttt {seqNum} field (provided in \texttt {eDescr} arg in profiler API \texttt {init()} function call) across ranks}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Multi-GPU single-thread-per-device trace: additionally showing proxy step events.}}{21}{figure.12}\protected@file@percent }
\newlabel{fig:multi-gpu-single-thread-show-proxystep}{{12}{21}{Multi-GPU single-thread-per-device trace: additionally showing proxy step events}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Multi-GPU single-thread-per-device trace: proxy step events, but always on new lane chronologically, no arrows.}}{22}{figure.13}\protected@file@percent }
\newlabel{fig:multi-gpu-single-thread-proxystep2}{{13}{22}{Multi-GPU single-thread-per-device trace: proxy step events, but always on new lane chronologically, no arrows}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Multi-GPU single-thread-per-device trace: from \texttt  {init} call until \texttt  {finalize} call (a small bar to the very right in the slightly darker top row).}}{23}{figure.14}\protected@file@percent }
\newlabel{fig:multi-gpu-single-thread-finalize}{{14}{23}{Multi-GPU single-thread-per-device trace: from \texttt {init} call until \texttt {finalize} call (a small bar to the very right in the slightly darker top row)}{figure.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Multiple Processes, Multiple Devices per Process, Single Threads per Process \& using ncclGroup}{23}{subsubsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}behavior when utilizing ncclGroup for collective operations}{23}{subsubsection.4.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Multi-GPU multiple communicators per process with grouped collectives: here 6 different communicator cliques across 4 processes are shown. their collective operations are grouped together with \texttt  {ncclGroupStart} and \texttt  {ncclGroupEnd}. Only a single \texttt  {GroupApi} event happens per process.}}{24}{figure.15}\protected@file@percent }
\newlabel{fig:multi-gpu-multi-comm-per-process-ncclgroup}{{15}{24}{Multi-GPU multiple communicators per process with grouped collectives: here 6 different communicator cliques across 4 processes are shown. their collective operations are grouped together with \texttt {ncclGroupStart} and \texttt {ncclGroupEnd}. Only a single \texttt {GroupApi} event happens per process}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Multi-GPU multiple communicators per process with grouped collectives: View of just a single process. The \texttt  {CollApi} events at the start show that they have the same GroupApi event as \texttt  {parentObj}. However each rank still emits their own \texttt  {KernelLaunch} event.}}{25}{figure.16}\protected@file@percent }
\newlabel{fig:multi-gpu-multi-comm-per-process-ncclgroup-1-process}{{16}{25}{Multi-GPU multiple communicators per process with grouped collectives: View of just a single process. The \texttt {CollApi} events at the start show that they have the same GroupApi event as \texttt {parentObj}. However each rank still emits their own \texttt {KernelLaunch} event}{figure.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}What is possible with the Profiler Plugin API? Considerations and Pitfalls for (logging, running metrics, CUPTI, \ldots  ) when writing the plugin - section title WIP }{25}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Performance and scalability of the Profiler Plugin API}{27}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Potential Integration with Score-P}{29}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion - What i have shown. Why would you use it? pros \& cons}{30}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}NCCL\_DEBUG}{30}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Known limitations}{30}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Summarize What i have shown TODO}{30}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}TODO}{31}{section.7}\protected@file@percent }
\gdef \@abspage@last{31}
